{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MinimalExample_Tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FernandoZR83/ANN_DL_ML/blob/master/MinimalExample_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akEgMV4sHT7A",
        "colab_type": "text"
      },
      "source": [
        "# This is an introduction to tensorflow 2.0 library\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfzgy_LAHf8H",
        "colab_type": "text"
      },
      "source": [
        "## Let us check out the tf version installed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn7CbiEDHcwk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "60e2cd77-8f21-4a8b-8b3f-25ac49df739a"
      },
      "source": [
        "!pip show tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 1.14.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: tensorboard, termcolor, numpy, wheel, gast, keras-preprocessing, six, grpcio, keras-applications, absl-py, astor, protobuf, wrapt, google-pasta, tensorflow-estimator\n",
            "Required-by: stable-baselines, magenta, fancyimpute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWvVRuFEHv_y",
        "colab_type": "text"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leb_GZyYHzfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn as sk\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TFOAEJgWear",
        "colab_type": "text"
      },
      "source": [
        "Data generation \n",
        "We need tensors to work with tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3pceV-lHzha",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eea8c96d-24a4-4887-a385-e7477f671316"
      },
      "source": [
        "#!rm -rf '/content/ANN_DL_ML/'\n",
        "!git clone 'https://github.com/FernandoZR83/ANN_DL_ML'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ANN_DL_ML' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYY-aZmEHzje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First, we should declare a variable containing the size of the training set we want to generate.\n",
        "observations = 100000\n",
        "\n",
        "# We will work with two variables as inputs. You can think about them as x1 and x2 in our previous examples.\n",
        "# We have picked x and z, since it is easier to differentiate them.\n",
        "# We generate them randomly, drawing from an uniform distribution. There are 3 arguments of this method (low, high, size).\n",
        "# The size of xs and zs is observations x 1. In this case: 1000 x 1.\n",
        "xs = np.random.uniform(low=-10, high=10, size=(observations,1))\n",
        "zs = np.random.uniform(-10, 10, (observations,1))\n",
        "\n",
        "# Combine the two dimensions of the input into one input matrix. \n",
        "# This is the X matrix from the linear model y = x*w + b.\n",
        "# column_stack is a Numpy method, which combines two matrices (vectors) into one.\n",
        "generated_inputs = np.column_stack((xs,zs))\n",
        "\n",
        "# We add a random small noise to the function i.e. f(x,z) = 2x - 3z + 5 + <small noise>\n",
        "noise = np.random.uniform(-1, 1, (observations,1))\n",
        "\n",
        "# Produce the targets according to our f(x,z) = 2x - 3z + 5 + noise definition.\n",
        "# In this way, we are basically saying: the weights should be 2 and -3, while the bias is 5.\n",
        "generated_targets = 2*xs - 3*zs + 5 + noise\n",
        "\n",
        "# save into an npz file called \"TF_intro\"\n",
        "np.savez('TF_intro', inputs=generated_inputs, targets=generated_targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOzMIBWXiABt",
        "colab_type": "text"
      },
      "source": [
        "Solving with tensor flow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ohe0y3tBHznr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data = np.load('/content/ANN_DL_ML/TF_intro.npz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-g1_uOnHzqT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d17912a2-2a6e-4a2f-ee02-77bb997eac8f"
      },
      "source": [
        "input_size = 2\n",
        "output_size = 1\n",
        "#We build the model, necessary when using tensorflow\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(output_size)\n",
        "    #tf.keras.layers.Dense(output size) takes the inputs provided to the model and \n",
        "    #calculates the dot productof the inputsand he weights and add bias\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer = 'sgd', loss = 'mean_squared_error')\n",
        "#model.compile(optimizer,loss) configures the model for training\n",
        "\n",
        "#Which deta tensorflow has to fit?\n",
        "#model.fit(inputs,targets) fits (trains) the model\n",
        "\n",
        "model.fit(training_data['inputs'], training_data['targets'], epochs = 100, verbose = 1) # verbose = 0 is for not showing progress bar"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0724 15:37:05.555935 140032364136320 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100000/100000 [==============================] - 8s 83us/sample - loss: 0.7793\n",
            "Epoch 2/100\n",
            "100000/100000 [==============================] - 4s 45us/sample - loss: 0.3464\n",
            "Epoch 3/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3458\n",
            "Epoch 4/100\n",
            "100000/100000 [==============================] - 4s 43us/sample - loss: 0.3461\n",
            "Epoch 5/100\n",
            "100000/100000 [==============================] - 5s 45us/sample - loss: 0.3456\n",
            "Epoch 6/100\n",
            "100000/100000 [==============================] - 5s 45us/sample - loss: 0.3457\n",
            "Epoch 7/100\n",
            "100000/100000 [==============================] - 5s 45us/sample - loss: 0.3462\n",
            "Epoch 8/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3460\n",
            "Epoch 9/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3460\n",
            "Epoch 10/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3458\n",
            "Epoch 11/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3457\n",
            "Epoch 12/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3459\n",
            "Epoch 13/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3457\n",
            "Epoch 14/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3454\n",
            "Epoch 15/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3454\n",
            "Epoch 16/100\n",
            "100000/100000 [==============================] - 4s 45us/sample - loss: 0.3459\n",
            "Epoch 17/100\n",
            "100000/100000 [==============================] - 4s 45us/sample - loss: 0.3457\n",
            "Epoch 18/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3459\n",
            "Epoch 19/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3462\n",
            "Epoch 20/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3459\n",
            "Epoch 21/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3459\n",
            "Epoch 22/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3465\n",
            "Epoch 23/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3452\n",
            "Epoch 24/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3463\n",
            "Epoch 25/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3463\n",
            "Epoch 26/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3455\n",
            "Epoch 27/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3460\n",
            "Epoch 28/100\n",
            "100000/100000 [==============================] - 4s 45us/sample - loss: 0.3459\n",
            "Epoch 29/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3460\n",
            "Epoch 30/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3460\n",
            "Epoch 31/100\n",
            "100000/100000 [==============================] - 4s 45us/sample - loss: 0.3460\n",
            "Epoch 32/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3451\n",
            "Epoch 33/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3465\n",
            "Epoch 34/100\n",
            "100000/100000 [==============================] - 4s 45us/sample - loss: 0.3455\n",
            "Epoch 35/100\n",
            "100000/100000 [==============================] - 4s 45us/sample - loss: 0.3461\n",
            "Epoch 36/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3460\n",
            "Epoch 37/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3461\n",
            "Epoch 38/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3456\n",
            "Epoch 39/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3457\n",
            "Epoch 40/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3459\n",
            "Epoch 41/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3454\n",
            "Epoch 42/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3460\n",
            "Epoch 43/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3465\n",
            "Epoch 44/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3462\n",
            "Epoch 45/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3459\n",
            "Epoch 46/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3463\n",
            "Epoch 47/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3456\n",
            "Epoch 48/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3456\n",
            "Epoch 49/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3460\n",
            "Epoch 50/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3454\n",
            "Epoch 51/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3460\n",
            "Epoch 52/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3465\n",
            "Epoch 53/100\n",
            "100000/100000 [==============================] - 4s 45us/sample - loss: 0.3463\n",
            "Epoch 54/100\n",
            "100000/100000 [==============================] - 4s 45us/sample - loss: 0.3464\n",
            "Epoch 55/100\n",
            "100000/100000 [==============================] - 4s 45us/sample - loss: 0.3457\n",
            "Epoch 56/100\n",
            "100000/100000 [==============================] - 4s 45us/sample - loss: 0.3461\n",
            "Epoch 57/100\n",
            "100000/100000 [==============================] - 4s 45us/sample - loss: 0.3454\n",
            "Epoch 58/100\n",
            "100000/100000 [==============================] - 5s 45us/sample - loss: 0.3467\n",
            "Epoch 59/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3457\n",
            "Epoch 60/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3453\n",
            "Epoch 61/100\n",
            "100000/100000 [==============================] - 4s 45us/sample - loss: 0.3462\n",
            "Epoch 62/100\n",
            "100000/100000 [==============================] - 4s 45us/sample - loss: 0.3455\n",
            "Epoch 63/100\n",
            "100000/100000 [==============================] - 4s 45us/sample - loss: 0.3460\n",
            "Epoch 64/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3458\n",
            "Epoch 65/100\n",
            "100000/100000 [==============================] - 4s 45us/sample - loss: 0.3461\n",
            "Epoch 66/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3455\n",
            "Epoch 67/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3461\n",
            "Epoch 68/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3460\n",
            "Epoch 69/100\n",
            "100000/100000 [==============================] - 4s 45us/sample - loss: 0.3458\n",
            "Epoch 70/100\n",
            "100000/100000 [==============================] - 5s 45us/sample - loss: 0.3461\n",
            "Epoch 71/100\n",
            "100000/100000 [==============================] - 4s 45us/sample - loss: 0.3461\n",
            "Epoch 72/100\n",
            "100000/100000 [==============================] - 5s 45us/sample - loss: 0.3459\n",
            "Epoch 73/100\n",
            "100000/100000 [==============================] - 4s 45us/sample - loss: 0.3460\n",
            "Epoch 74/100\n",
            "100000/100000 [==============================] - 4s 45us/sample - loss: 0.3456\n",
            "Epoch 75/100\n",
            "100000/100000 [==============================] - 5s 46us/sample - loss: 0.3460\n",
            "Epoch 76/100\n",
            "100000/100000 [==============================] - 5s 46us/sample - loss: 0.3456\n",
            "Epoch 77/100\n",
            "100000/100000 [==============================] - 5s 45us/sample - loss: 0.3459\n",
            "Epoch 78/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3461\n",
            "Epoch 79/100\n",
            "100000/100000 [==============================] - 4s 45us/sample - loss: 0.3458\n",
            "Epoch 80/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3459\n",
            "Epoch 81/100\n",
            "100000/100000 [==============================] - 4s 45us/sample - loss: 0.3457\n",
            "Epoch 82/100\n",
            "100000/100000 [==============================] - 4s 45us/sample - loss: 0.3456\n",
            "Epoch 83/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3454\n",
            "Epoch 84/100\n",
            "100000/100000 [==============================] - 5s 46us/sample - loss: 0.3463\n",
            "Epoch 85/100\n",
            "100000/100000 [==============================] - 5s 45us/sample - loss: 0.3464\n",
            "Epoch 86/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3460\n",
            "Epoch 87/100\n",
            "100000/100000 [==============================] - 4s 45us/sample - loss: 0.3462\n",
            "Epoch 88/100\n",
            "100000/100000 [==============================] - 4s 45us/sample - loss: 0.3456\n",
            "Epoch 89/100\n",
            "100000/100000 [==============================] - 4s 45us/sample - loss: 0.3463\n",
            "Epoch 90/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3464\n",
            "Epoch 91/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3463\n",
            "Epoch 92/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3458\n",
            "Epoch 93/100\n",
            "100000/100000 [==============================] - 4s 45us/sample - loss: 0.3454\n",
            "Epoch 94/100\n",
            "100000/100000 [==============================] - 4s 45us/sample - loss: 0.3454\n",
            "Epoch 95/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3460\n",
            "Epoch 96/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3458\n",
            "Epoch 97/100\n",
            "100000/100000 [==============================] - 4s 45us/sample - loss: 0.3457\n",
            "Epoch 98/100\n",
            "100000/100000 [==============================] - 4s 45us/sample - loss: 0.3458\n",
            "Epoch 99/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3462\n",
            "Epoch 100/100\n",
            "100000/100000 [==============================] - 4s 44us/sample - loss: 0.3456\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5b867edcc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx_1vYSapHM5",
        "colab_type": "text"
      },
      "source": [
        "Extract weights and biases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2KCwCU8HzvV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a0a2064a-defe-41e9-a4f8-86f9a2665684"
      },
      "source": [
        "#[0] is the position layer whose weights we are interested in\n",
        "model.layers[0].get_weights()\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 2.006739 ],\n",
              "        [-2.9880488]], dtype=float32), array([5.0060725], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPer9FXBHzx_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e464677f-f093-421e-9347-772551b3a674"
      },
      "source": [
        "weights = model.layers[0].get_weights()[0]\n",
        "weights"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2.006739 ],\n",
              "       [-2.9880488]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l3WX-sVHz0R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9274645e-2ebc-46b5-c60f-5c315e43c7f0"
      },
      "source": [
        "bias = model.layers[0].get_weights()[1]\n",
        "bias"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5.0060725], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSIyH154qbGy",
        "colab_type": "text"
      },
      "source": [
        "Extract the outputs (Make predictions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "colRBvF9Hzlw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "d08d3b82-0707-4b3a-9797-6721b1c84f97"
      },
      "source": [
        "model.predict_on_batch(training_data['inputs'])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 32.70417  ],\n",
              "       [ 16.019907 ],\n",
              "       [ -5.9503455],\n",
              "       ...,\n",
              "       [  2.980986 ],\n",
              "       [-35.503906 ],\n",
              "       [  9.173231 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvAYDLtAq0kE",
        "colab_type": "text"
      },
      "source": [
        "Compare results to targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX4uJED7q3KT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "b675eb98-c651-4c47-ee6d-974ec24d9e0d"
      },
      "source": [
        "model.predict_on_batch(training_data['inputs']).round(1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 32.7],\n",
              "       [ 16. ],\n",
              "       [ -6. ],\n",
              "       ...,\n",
              "       [  3. ],\n",
              "       [-35.5],\n",
              "       [  9.2]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0yYAMLTq3NE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "d0d86b44-a64d-4e59-9c10-cc630d8408de"
      },
      "source": [
        "training_data['targets'].round(1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 32.3],\n",
              "       [ 15.8],\n",
              "       [ -6. ],\n",
              "       ...,\n",
              "       [  2.5],\n",
              "       [-35.1],\n",
              "       [ 10.2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBz18J1urcFp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "26f7ed24-660a-4bff-e620-c933c4c6503d"
      },
      "source": [
        "plt.plot(np.squeeze(model.predict_on_batch(training_data['inputs'])),np.squeeze(training_data['targets']))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5bab275b70>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngNOndpUFAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Fk97rV6tyfk",
        "colab_type": "text"
      },
      "source": [
        "Customizing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZxPhB9btxIR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e1647b9d-9f1e-4563-89ac-04e8b111999f"
      },
      "source": [
        "input_size = 2\n",
        "output_size = 1\n",
        "#We build the model, necessary when using tensorflow\n",
        "\n",
        "#tf.keras.layers.Dense(output size) takes the inputs provided to the model and \n",
        "#calculates the dot productof the inputsand he weights and add bias\n",
        "#kernel_initializer and bias initializer initialize weights and biases\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(output_size,\n",
        "                          kernel_initializer = tf.random_uniform_initializer(minval=-0.1,maxval=0.1),\n",
        "                          bias_initializer = tf.random_uniform_initializer(minval=-0.1,maxval=0.1)\n",
        "                         )\n",
        "])\n",
        "#Customize optimizer\n",
        "custom_optimizer = tf.keras.optimizers.SGD(learning_rate=0.02)\n",
        "model.compile(optimizer = custom_optimizer, loss = 'mean_squared_error')\n",
        "#model.compile(optimizer,loss) configures the model for training\n",
        "\n",
        "#Which deta tensorflow has to fit?\n",
        "#model.fit(inputs,targets) fits (trains) the model\n",
        "\n",
        "model.fit(training_data['inputs'], training_data['targets'], epochs = 100, verbose = 2) # verbose = 0 is for not showing progress bar"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100000/100000 - 4s - loss: 0.6485\n",
            "Epoch 2/100\n",
            "100000/100000 - 4s - loss: 0.3823\n",
            "Epoch 3/100\n",
            "100000/100000 - 4s - loss: 0.3808\n",
            "Epoch 4/100\n",
            "100000/100000 - 4s - loss: 0.3839\n",
            "Epoch 5/100\n",
            "100000/100000 - 4s - loss: 0.3819\n",
            "Epoch 6/100\n",
            "100000/100000 - 4s - loss: 0.3799\n",
            "Epoch 7/100\n",
            "100000/100000 - 4s - loss: 0.3802\n",
            "Epoch 8/100\n",
            "100000/100000 - 4s - loss: 0.3818\n",
            "Epoch 9/100\n",
            "100000/100000 - 4s - loss: 0.3829\n",
            "Epoch 10/100\n",
            "100000/100000 - 4s - loss: 0.3843\n",
            "Epoch 11/100\n",
            "100000/100000 - 4s - loss: 0.3810\n",
            "Epoch 12/100\n",
            "100000/100000 - 4s - loss: 0.3835\n",
            "Epoch 13/100\n",
            "100000/100000 - 4s - loss: 0.3809\n",
            "Epoch 14/100\n",
            "100000/100000 - 4s - loss: 0.3836\n",
            "Epoch 15/100\n",
            "100000/100000 - 4s - loss: 0.3830\n",
            "Epoch 16/100\n",
            "100000/100000 - 4s - loss: 0.3834\n",
            "Epoch 17/100\n",
            "100000/100000 - 4s - loss: 0.3847\n",
            "Epoch 18/100\n",
            "100000/100000 - 4s - loss: 0.3813\n",
            "Epoch 19/100\n",
            "100000/100000 - 4s - loss: 0.3840\n",
            "Epoch 20/100\n",
            "100000/100000 - 4s - loss: 0.3829\n",
            "Epoch 21/100\n",
            "100000/100000 - 4s - loss: 0.3795\n",
            "Epoch 22/100\n",
            "100000/100000 - 4s - loss: 0.3836\n",
            "Epoch 23/100\n",
            "100000/100000 - 4s - loss: 0.3827\n",
            "Epoch 24/100\n",
            "100000/100000 - 4s - loss: 0.3856\n",
            "Epoch 25/100\n",
            "100000/100000 - 4s - loss: 0.3835\n",
            "Epoch 26/100\n",
            "100000/100000 - 4s - loss: 0.3813\n",
            "Epoch 27/100\n",
            "100000/100000 - 4s - loss: 0.3784\n",
            "Epoch 28/100\n",
            "100000/100000 - 4s - loss: 0.3834\n",
            "Epoch 29/100\n",
            "100000/100000 - 4s - loss: 0.3805\n",
            "Epoch 30/100\n",
            "100000/100000 - 4s - loss: 0.3828\n",
            "Epoch 31/100\n",
            "100000/100000 - 4s - loss: 0.3825\n",
            "Epoch 32/100\n",
            "100000/100000 - 4s - loss: 0.3818\n",
            "Epoch 33/100\n",
            "100000/100000 - 4s - loss: 0.3830\n",
            "Epoch 34/100\n",
            "100000/100000 - 4s - loss: 0.3838\n",
            "Epoch 35/100\n",
            "100000/100000 - 4s - loss: 0.3836\n",
            "Epoch 36/100\n",
            "100000/100000 - 4s - loss: 0.3801\n",
            "Epoch 37/100\n",
            "100000/100000 - 4s - loss: 0.3837\n",
            "Epoch 38/100\n",
            "100000/100000 - 4s - loss: 0.3834\n",
            "Epoch 39/100\n",
            "100000/100000 - 4s - loss: 0.3819\n",
            "Epoch 40/100\n",
            "100000/100000 - 4s - loss: 0.3809\n",
            "Epoch 41/100\n",
            "100000/100000 - 4s - loss: 0.3842\n",
            "Epoch 42/100\n",
            "100000/100000 - 4s - loss: 0.3838\n",
            "Epoch 43/100\n",
            "100000/100000 - 4s - loss: 0.3829\n",
            "Epoch 44/100\n",
            "100000/100000 - 4s - loss: 0.3830\n",
            "Epoch 45/100\n",
            "100000/100000 - 4s - loss: 0.3838\n",
            "Epoch 46/100\n",
            "100000/100000 - 4s - loss: 0.3829\n",
            "Epoch 47/100\n",
            "100000/100000 - 4s - loss: 0.3813\n",
            "Epoch 48/100\n",
            "100000/100000 - 4s - loss: 0.3812\n",
            "Epoch 49/100\n",
            "100000/100000 - 4s - loss: 0.3789\n",
            "Epoch 50/100\n",
            "100000/100000 - 4s - loss: 0.3825\n",
            "Epoch 51/100\n",
            "100000/100000 - 4s - loss: 0.3836\n",
            "Epoch 52/100\n",
            "100000/100000 - 4s - loss: 0.3841\n",
            "Epoch 53/100\n",
            "100000/100000 - 4s - loss: 0.3808\n",
            "Epoch 54/100\n",
            "100000/100000 - 4s - loss: 0.3839\n",
            "Epoch 55/100\n",
            "100000/100000 - 4s - loss: 0.3826\n",
            "Epoch 56/100\n",
            "100000/100000 - 4s - loss: 0.3799\n",
            "Epoch 57/100\n",
            "100000/100000 - 4s - loss: 0.3803\n",
            "Epoch 58/100\n",
            "100000/100000 - 4s - loss: 0.3817\n",
            "Epoch 59/100\n",
            "100000/100000 - 4s - loss: 0.3835\n",
            "Epoch 60/100\n",
            "100000/100000 - 4s - loss: 0.3828\n",
            "Epoch 61/100\n",
            "100000/100000 - 4s - loss: 0.3807\n",
            "Epoch 62/100\n",
            "100000/100000 - 4s - loss: 0.3824\n",
            "Epoch 63/100\n",
            "100000/100000 - 4s - loss: 0.3821\n",
            "Epoch 64/100\n",
            "100000/100000 - 4s - loss: 0.3829\n",
            "Epoch 65/100\n",
            "100000/100000 - 4s - loss: 0.3829\n",
            "Epoch 66/100\n",
            "100000/100000 - 4s - loss: 0.3831\n",
            "Epoch 67/100\n",
            "100000/100000 - 4s - loss: 0.3803\n",
            "Epoch 68/100\n",
            "100000/100000 - 4s - loss: 0.3816\n",
            "Epoch 69/100\n",
            "100000/100000 - 4s - loss: 0.3783\n",
            "Epoch 70/100\n",
            "100000/100000 - 4s - loss: 0.3815\n",
            "Epoch 71/100\n",
            "100000/100000 - 4s - loss: 0.3847\n",
            "Epoch 72/100\n",
            "100000/100000 - 4s - loss: 0.3828\n",
            "Epoch 73/100\n",
            "100000/100000 - 4s - loss: 0.3840\n",
            "Epoch 74/100\n",
            "100000/100000 - 4s - loss: 0.3810\n",
            "Epoch 75/100\n",
            "100000/100000 - 4s - loss: 0.3839\n",
            "Epoch 76/100\n",
            "100000/100000 - 4s - loss: 0.3814\n",
            "Epoch 77/100\n",
            "100000/100000 - 4s - loss: 0.3801\n",
            "Epoch 78/100\n",
            "100000/100000 - 4s - loss: 0.3847\n",
            "Epoch 79/100\n",
            "100000/100000 - 4s - loss: 0.3858\n",
            "Epoch 80/100\n",
            "100000/100000 - 4s - loss: 0.3823\n",
            "Epoch 81/100\n",
            "100000/100000 - 4s - loss: 0.3830\n",
            "Epoch 82/100\n",
            "100000/100000 - 4s - loss: 0.3809\n",
            "Epoch 83/100\n",
            "100000/100000 - 4s - loss: 0.3829\n",
            "Epoch 84/100\n",
            "100000/100000 - 4s - loss: 0.3811\n",
            "Epoch 85/100\n",
            "100000/100000 - 4s - loss: 0.3822\n",
            "Epoch 86/100\n",
            "100000/100000 - 4s - loss: 0.3834\n",
            "Epoch 87/100\n",
            "100000/100000 - 4s - loss: 0.3829\n",
            "Epoch 88/100\n",
            "100000/100000 - 4s - loss: 0.3811\n",
            "Epoch 89/100\n",
            "100000/100000 - 4s - loss: 0.3833\n",
            "Epoch 90/100\n",
            "100000/100000 - 4s - loss: 0.3834\n",
            "Epoch 91/100\n",
            "100000/100000 - 4s - loss: 0.3818\n",
            "Epoch 92/100\n",
            "100000/100000 - 4s - loss: 0.3813\n",
            "Epoch 93/100\n",
            "100000/100000 - 4s - loss: 0.3813\n",
            "Epoch 94/100\n",
            "100000/100000 - 4s - loss: 0.3844\n",
            "Epoch 95/100\n",
            "100000/100000 - 4s - loss: 0.3831\n",
            "Epoch 96/100\n",
            "100000/100000 - 4s - loss: 0.3831\n",
            "Epoch 97/100\n",
            "100000/100000 - 4s - loss: 0.3835\n",
            "Epoch 98/100\n",
            "100000/100000 - 4s - loss: 0.3791\n",
            "Epoch 99/100\n",
            "100000/100000 - 4s - loss: 0.3837\n",
            "Epoch 100/100\n",
            "100000/100000 - 4s - loss: 0.3784\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5bab26db38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugrCH09jxIOU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2d731c83-1f1e-46f4-d721-2678c866ce38"
      },
      "source": [
        "#[0] is the position layer whose weights we are interested in\n",
        "model.layers[0].get_weights()\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 2.0060322],\n",
              "        [-3.018317 ]], dtype=float32), array([5.0068145], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEsjj9hDxIhc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "927a53ce-2972-4fe2-b7f5-e469a8b46263"
      },
      "source": [
        "weights = model.layers[0].get_weights()[0]\n",
        "weights"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2.0060322],\n",
              "       [-3.018317 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMdryUxvxIsI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2824fe96-32b9-4be0-f3a1-9a5a62158cca"
      },
      "source": [
        "bias = model.layers[0].get_weights()[1]\n",
        "bias"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5.0068145], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djbDCxixxTf7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "c7d0b4d8-b0b8-4c19-a7e2-2496905b4aa0"
      },
      "source": [
        "model.predict_on_batch(training_data['inputs'])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 32.98804  ],\n",
              "       [ 16.131798 ],\n",
              "       [ -6.1845613],\n",
              "       ...,\n",
              "       [  3.0987716],\n",
              "       [-35.7277   ],\n",
              "       [  9.381792 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOpgfs9ExTk0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "d66dcf66-db99-4fc3-ff54-e8dd52c52c78"
      },
      "source": [
        "model.predict_on_batch(training_data['inputs']).round(1)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 33. ],\n",
              "       [ 16.1],\n",
              "       [ -6.2],\n",
              "       ...,\n",
              "       [  3.1],\n",
              "       [-35.7],\n",
              "       [  9.4]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgE6vil-xTqr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "d6323635-3d2d-4406-a3a7-0cc5a9a12795"
      },
      "source": [
        "training_data['inputs'].round(1)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.1, -9.4],\n",
              "       [ 0. , -3.7],\n",
              "       [ 5.9,  7.6],\n",
              "       ...,\n",
              "       [-6.5, -3.7],\n",
              "       [-8.8,  7.6],\n",
              "       [-7.9, -6.7]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHxBQYv_xToV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "211c251e-8ed1-4c84-add3-b9d93f035058"
      },
      "source": [
        "plt.plot(np.squeeze(model.predict_on_batch(training_data['inputs'])),np.squeeze(training_data['targets']))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5b78599400>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFPBJREFUeJzt3X+wXWV97/H3NwmQWoHwIyCSpDkW\n0IlVlJ4JaFqrhkIIXOOdcRhax4LSpj/QsVYLhPQH0wJivVeko9LmSnvlDm3gopa0DVhAGX8GTARE\nCMEYwCQNEEUEUUhPzrd/7BXchJNk77PX2r/W+zXDnL3WfvZez2LnfM53P+t59o7MRJJUL1N63QFJ\nUvcZ/pJUQ4a/JNWQ4S9JNWT4S1INGf6SVEOGvyTVUCnhHxEzIuKGiHggItZHxBsi4tCIuCUivlv8\nPKSMY0mSOldW5X8lcHNmvgo4HlgPXAjclpnHArcV25KkPhCdrvCNiIOBu4FXZNOTRcQG4M2ZuS0i\njgJuz8xX7u25Dj/88Jw7d25H/ZGkulm3bt0PMnNmO4+ZVsJxR4DtwD9GxPHAOuD9wJGZua1o8yhw\n5EQPjoilwFKAOXPmsHbt2hK6JEn1ERGPtPuYMoZ9pgEnAFdl5uuBZ9htiKd4RzDhW4zMXJGZo5k5\nOnNmW3+4JEmTVEb4bwG2ZOYdxfYNNP4YPFYM91D8fLyEY0mSStBx+Gfmo8DmiNg1nr8QuB9YBZxd\n7DsbuLHTY0mSylHGmD/A+4BrI2J/YBPwbhp/WK6PiHOBR4AzSzqWJKlDpYR/Zt4NjE5w18Iynl+S\nVC5X+EpSDRn+klRDhr8k9dCz/7WTK255kP988mddPW5ZF3wlSW145IfP8Bsfvf357aMOns5Z8+d0\n7fiGvyR12dwL//1F+974y4d3tQ+GvyR1yYLLv8jWPQzvPPzDZ5hz2Eu61hfDX5Iq9sOfPMevXnLr\nXtu86bjufryN4S9JFZpoiGd317xnfhd68kKGvyRV4Krbv8dHbn5gn+3+6XdP5I3HdHe8Hwx/SSpV\nZjKybHVLbTdcsogDpk2tuEcTM/wlqSStDPHs8vDlp1fYk30z/CWpQ2M7xzlm+U0ttX3wktPYf1rv\n19ca/pLUgUGq9psZ/pI0CRsefZpTP/7lltp+77LFTJ0SFfeoPYa/JLVpUKv9Zoa/JLXorf/7djZt\nf6altv0a+rsY/pLUgmGo9psZ/pK0F8MW+rv0fr6RJPWhzGw5+N/+upcPVPCDlb8kvciwVvvNDH9J\nKvzgJ88xuo9P39zl1j95E8cccWDFPaqO4S9J1KPab2b4S6q1v7jxO1zzjUdaatsvH81QBsNfUm3V\nrdpvZvhLqp06h/4uw/H+RZJaZPA3WPlLqgVD/4Ws/CUNtXYWa0E9gh+s/CUNMUN/zwx/SUNn65M/\nY8HlX2yp7Z+e+krOe8sxFfeo/5QW/hExFVgLbM3MMyJiBFgJHAasA96VmTvKOp4kTcRqvzVlVv7v\nB9YDBxXbHwGuyMyVEfF3wLnAVSUeT5Ke9/ZPfo27Nz/ZUttvX3wKB03fr+Ie9bdSLvhGxCzgdODT\nxXYAbwVuKJp8Bnh7GceSpN3NvfDfWw7+hy8/vfbBD+VV/h8Hzgd2fcrRYcCTmTlWbG8Bji7pWJIE\ntDfE89CHF9OoSwUlVP4RcQbweGaum+Tjl0bE2ohYu3379k67I6km2h3bN/hfqIzKfwHwtohYDEyn\nMeZ/JTAjIqYV1f8sYOtED87MFcAKgNHR0SyhP5KGmBd0y9Fx5Z+ZyzJzVmbOBc4CvpiZ7wS+BLyj\naHY2cGOnx5JUX+PjLtYqU5Xz/C8AVkbEJcBdwNUVHkvSEDP0y1dq+Gfm7cDtxe1NwPwyn19SvTz2\n1LOceNltLbV9+cHT+fqyhRX3aHi4wldSX7Lar5bhL6mvLPnk17inxTn7X/rQmxk5/Bcr7tFwMvwl\n9Q2r/e4x/CX1XDuhv+myxUyZ4pz9Thn+knrKar83DH9JPeFHM/SW4S+pqzKTkWWrW25vtV8Nw19S\n1zjE0z/8Dl9JlXv86WcN/j5j5S+pUoZ+fzL8JVXiuOU3sWPneEttP/XOE1j8mqMq7pGaGf6SSme1\n3/8Mf0mlaSf0H7zkNPaf5mXHXjH8JZXCan+wGP6SOuJircHkey5Jk7JzEt+sZfD3Dyt/SW1ziGfw\nWflLatm6R54w+IeElb+klhj6w8Xwl7RX7YT+n58xj3N/baTC3qgshr+kPbLaH16Gv6QXaSf07/mL\nUzj4JftV2BtVwfCX9AJW+/Vg+EsCXKxVN071lGrOxVr1ZOUv1ZhDPPVl5S/V0IZHnzb4a87KX6oZ\nQ19g+Eu10U7o/96vj7D89HkV9ka9ZvhLNWC1r911HP4RMRu4BjgSSGBFZl4ZEYcC1wFzgYeBMzPz\nR50eT1Lr2gn9r5z/FmYf+pIKe6N+UsYF3zHgg5k5DzgJOC8i5gEXArdl5rHAbcW2pC7IbH/6psFf\nLx1X/pm5DdhW3H46ItYDRwNLgDcXzT4D3A5c0OnxJO1dO6H/vcsWM3WKc/brqNQx/4iYC7weuAM4\nsvjDAPAojWEhSRUZ2znOMctvarm9Y/v1Vlr4R8RLgc8Cf5yZTzWvAMzMjIjcw+OWAksB5syZU1Z3\npFrxgq7aVcoir4jYj0bwX5uZnyt2PxYRRxX3HwU8PtFjM3NFZo5m5ujMmTPL6I5UG/dsftLg16SU\nMdsngKuB9Zn5saa7VgFnA5cXP2/s9FiSfs7QVyfKGPZZALwLuDci7i72XUQj9K+PiHOBR4AzSziW\nVHvthP7MAw/gm8tPrrA3GlRlzPb5KrCn6QILO31+ST9nta+yuMJXGgDthP6q9y7gtbNmVNgbDQPD\nX+pjmcnIstUtt7faV6sMf6lPuVhLVTL8pT7jYi11g+Ev9REv6Kpb/CYvqQ/csemHBr+6yspf6jFD\nX71g+Es90k7og8Gvchn+Ug9Y7avXDH+pi9oJ/ZVLT+KkVxxWYW9UZ4a/1CVW++onhr9UsXZCf8Ml\nizhg2tQKeyM1GP5SRXaMjXPcn7lYS/3J8Jcq0E61/9CHF9P8zXdSN7jISyrR7Rseb3ts3+BXL1j5\nSyXxgq4GieEvdcjFWhpEhr/UAat9DSrDX5qEdkL/b97xWs4cnV1hb6T2Gf5SG/xmLQ0Lw19qUTvV\n/gN/vYjp+7lYS/3L8Jf24dn/2smr/vzmlttb7WsQGP7SXrhYS8PKRV7SBP7fmkdcrKWhZuUv7cbp\nm6oDw18quFhLdWL4S1jtq34Mf9VaO6H/2T98I7/6S4dU2Bupewx/1ZKLtVR3hr9qp51q/7uXnsZ+\nU50Up+FT+b/qiFgUERsiYmNEXFj18aQ92TE23vbYvsGvYVVp5R8RU4FPAr8JbAG+GRGrMvP+Ko8r\n7c4LutILVV3WzAc2ZuamzNwBrASWVHxM6Xn/58ubDH5pAlWP+R8NbG7a3gKcWPExJcBqX9qbnl/w\njYilwFKAOXPm9Lg3GgYu1pL2rerw3wo0f4vFrGLf8zJzBbACYHR0NCvuj4ac1b7UmqrD/5vAsREx\nQiP0zwJ+u+JjqobaCf1/OW8Br5s9o8LeSP2v0vDPzLGIeC/wBWAq8A+ZeV+Vx1S9uFhLmpzKx/wz\nczXQ+m+n1KJ2qv1Nly1myhQ/clnaxRUsGjg/eW6s7bF9g196oZ7P9pHa4QVdqRxW/hoIN39nm8Ev\nlcjKX33P0JfKZ/irb7lYS6qO4a++ZLUvVcvwV19pJ/S/cv5bmH3oSyrsjTS8DH/1BRdrSd1l+Kvn\n2qn2N156GtP8ghWpY4a/embH2DjH/dlNLbe32pfKY/irJ9qp9h/68GIiXKErlcn3z+qqOx96ou2Z\nPAa/VD4rf3WN0zel/mH4q3LthP7+U6fw4KWnVdgbSWD4q2JW+1J/MvxViXZC/6sXvIVZh7hYS+om\nw1+ls9qX+p/hr9L4zVrS4HCqpzo2tnPcb9aSBoyVvzriEI80mKz8NSnrtz1l8EsDzMpfbTP0pcFn\n+Ktl7YT+iSOHct3vv6HC3kjqhOGvlljtS8PF8NdetRP6a5Yt5GUHT6+wN5LKYvhrj6z2peFl+OtF\n/Kx9afg51VPPGx9PP2tfqgkrfwEO8Uh1Y+Vfc4899azBL9WQlX+NGfpSfXVU+UfERyPigYj4dkR8\nPiJmNN23LCI2RsSGiDi1866qLB+47u6Wg//4WQcb/NIQ6rTyvwVYlpljEfERYBlwQUTMA84CXg28\nHLg1Io7LzJ0dHk8dstqXBB2Gf2b+R9PmGuAdxe0lwMrMfA54KCI2AvOBb3RyPE1eO6H/tQvfytEz\nfqHC3kjqtTIv+L4HuKm4fTSwuem+LcW+F4mIpRGxNiLWbt++vcTuaJd2q32DXxp++6z8I+JW4GUT\n3LU8M28s2iwHxoBr2+1AZq4AVgCMjo5mu4/XnvnNWpL2ZJ/hn5kn7+3+iDgHOANYmJm7wnsrMLup\n2axin7ogMxlZtrrl9o7tS/XT0Zh/RCwCzgd+IzN/2nTXKuCfIuJjNC74Hgvc2cmx1Bov6EpqRaez\nfT4BHADcUizzX5OZf5CZ90XE9cD9NIaDznOmT7V+8twYv/KXX2i5vcEv1Vuns32O2ct9lwKXdvL8\nao3VvqR2+fEOA+zqrz7UcvAfd+RLDX5Jz/PjHQaU1b6kThj+A8Zv1pJUBsN/gFjtSyqL4T8A/GYt\nSWUz/PuYi7UkVcXw71MO8UiqklM9+8yOsXGDX1LlrPz7iKEvqVus/PvAd7b+uOXgP+kVhxr8kjpm\n5d9jVvuSesHw75FTr/gyGx57uqW2dy5fyBEHulhLUnkM/x6w2pfUa4Z/F7lYS1K/MPy7xGpfUj8x\n/Ctm6EvqR071rMj4eBr8kvqWlX8FDH1J/c7Kv0RPPLOj5eD/0CnHGfySesbKvyRW+5IGieHfoWWf\nu5d/vvP7LbVd/1eL+IX9p1bcI0naN8O/A1b7kgaV4T8JLtaSNOgM/zZZ7UsaBoZ/iwx9ScPEqZ77\n0M5irSMOPMDglzQQrPz3wmpf0rAy/CfwzHNjvPovv9BS28//0Rt5/ZxDKu6RJJXL8N+N1b6kOjD8\nC3d9/0f8z099vaW2D/z1Iqbv52ItSYOrlPCPiA8C/wuYmZk/iMbE9iuBxcBPgXMy81tlHKsKVvuS\n6qbj8I+I2cApQPNnHJwGHFv8dyJwVfGzr5y14hus2fRES21drCVpmJRR+V8BnA/c2LRvCXBNZiaw\nJiJmRMRRmbmthOOVwmpfUp11FP4RsQTYmpn37FYVHw1sbtreUuzrefh/ePV6/v7Lm1pqa+hLGlb7\nDP+IuBV42QR3LQcuojHkM2kRsRRYCjBnzpxOnmqfWq32//n3TuINv3xYpX2RpF7aZ/hn5skT7Y+I\n1wAjwK6qfxbwrYiYD2wFZjc1n1Xsm+j5VwArAEZHR7OdzrfqQ///Hm5Yt6Wltlb7kupg0sM+mXkv\ncMSu7Yh4GBgtZvusAt4bEStpXOj9cS/G+8fHk1dctLqltt+++BQOmr5fxT2SpP5Q1Tz/1TSmeW6k\nMdXz3RUdZ48+cN3dfP6uCd9svIjVvqS6KS38M3Nu0+0EzivrudsxtnOcY5bf1FLb7122mKlTnL4p\nqX6G6lM9P/2VTS0F//GzZ/Dw5acb/JJqa2g+3uHiVffxf7/+8D7bOcQjSUMS/pm5z+D/l/MW8LrZ\nM7rTIUnqc0MR/puf+Nle77fal6QXGorwn77/xJcu/PRNSZrYUIT/EQdO5+L/MY+L//V+PnDycbz6\n5Qdx8rwje90tSepbQxH+AOcsGOGcBSO97oYkDYShmuopSWqN4S9JNWT4S1INGf6SVEOGvyTVkOEv\nSTVk+EtSDRn+klRD0fjo/f4QEduBR3p0+MOBH/To2L3iOQ+/up0v1POcX5mZB7bzgL5a4ZuZM3t1\n7IhYm5mjvTp+L3jOw69u5wv1Ped2H+OwjyTVkOEvSTVk+P/cil53oAc85+FXt/MFz7klfXXBV5LU\nHVb+klRDhn8hIj4YERkRhxfbERF/GxEbI+LbEXFCr/tYloj4aEQ8UJzX5yNiRtN9y4pz3hARp/ay\nn2WKiEXFOW2MiAt73Z8qRMTsiPhSRNwfEfdFxPuL/YdGxC0R8d3i5yG97muZImJqRNwVEf9WbI9E\nxB3Fa31dROzf6z6WKSJmRMQNxe/w+oh4w2ReY8Ofxi8NcArw/abdpwHHFv8tBa7qQdeqcgvwK5n5\nWuBBYBlARMwDzgJeDSwCPhURA/89mMU5fJLGazoP+K3iXIfNGPDBzJwHnAScV5znhcBtmXkscFux\nPUzeD6xv2v4IcEVmHgP8CDi3J72qzpXAzZn5KuB4Gufe9mts+DdcAZwPNF8AWQJckw1rgBkRcVRP\neleyzPyPzBwrNtcAs4rbS4CVmflcZj4EbATm96KPJZsPbMzMTZm5A1hJ41yHSmZuy8xvFbefphEK\nR9M4188UzT4DvL03PSxfRMwCTgc+XWwH8FbghqLJsJ3vwcCbgKsBMnNHZj7JJF7j2od/RCwBtmbm\nPbvddTSwuWl7S7Fv2LwHuKm4PaznPKzntUcRMRd4PXAHcGRmbivuehQYpi+4/jiNwm282D4MeLKp\nuBm213oE2A78YzHU9emI+EUm8Rr31QrfqkTErcDLJrhrOXARjSGfobK3c87MG4s2y2kMFVzbzb6p\nWhHxUuCzwB9n5lONYrghMzMihmKKX0ScATyemesi4s297k+XTANOAN6XmXdExJXsNsTT6mtci/DP\nzJMn2h8Rr6Hxl/Se4hdkFvCtiJgPbAVmNzWfVewbCHs6510i4hzgDGBh/ny+70Cf814M63m9SETs\nRyP4r83MzxW7H4uIozJzWzF0+XjveliqBcDbImIxMB04iMZ4+IyImFZU/8P2Wm8BtmTmHcX2DTTC\nv+3XuNbDPpl5b2YekZlzM3Mujf+xJ2Tmo8Aq4HeKWT8nAT9uels10CJiEY23ym/LzJ823bUKOCsi\nDoiIERoXu+/sRR9L9k3g2GIWyP40Lmqv6nGfSleMd18NrM/MjzXdtQo4u7h9NnBjt/tWhcxclpmz\nit/ds4AvZuY7gS8B7yiaDc35AhTZtDkiXlnsWgjczyRe41pU/pO0GlhM46LnT4F397Y7pfoEcABw\nS/GOZ01m/kFm3hcR19P4xzQGnJeZO3vYz1Jk5lhEvBf4AjAV+IfMvK/H3arCAuBdwL0RcXex7yLg\ncuD6iDiXxqfmntmj/nXLBcDKiLgEuIvi4ugQeR9wbVHIbKKRTVNo8zV2ha8k1VCth30kqa4Mf0mq\nIcNfkmrI8JekGjL8JamGDH9JqiHDX5JqyPCXpBr6by8NsUG5W9kBAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPRWNia6x0Fg",
        "colab_type": "text"
      },
      "source": [
        "Using the same code as before, please solve the following exercises\n",
        "\n",
        "1. Change the number of observations to 1000,000 and see what happens.\n",
        "\n",
        "2. Play around with the learning rate. Values like 0.0001, 0.001, 0.1, 1 are all interesting to observe.\n",
        "\n",
        "3. Change the loss function. An alternative loss for regressions is the Huber loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iam9U-VMx1wN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First, we should declare a variable containing the size of the training set we want to generate.\n",
        "observations = 1000000\n",
        "\n",
        "# We will work with two variables as inputs. You can think about them as x1 and x2 in our previous examples.\n",
        "# We have picked x and z, since it is easier to differentiate them.\n",
        "# We generate them randomly, drawing from an uniform distribution. There are 3 arguments of this method (low, high, size).\n",
        "# The size of xs and zs is observations x 1. In this case: 1000 x 1.\n",
        "xs = np.random.uniform(low=-10, high=10, size=(observations,1))\n",
        "zs = np.random.uniform(-10, 10, (observations,1))\n",
        "\n",
        "# Combine the two dimensions of the input into one input matrix. \n",
        "# This is the X matrix from the linear model y = x*w + b.\n",
        "# column_stack is a Numpy method, which combines two matrices (vectors) into one.\n",
        "generated_inputs = np.column_stack((xs,zs))\n",
        "\n",
        "# We add a random small noise to the function i.e. f(x,z) = 2x - 3z + 5 + <small noise>\n",
        "noise = np.random.uniform(-1, 1, (observations,1))\n",
        "\n",
        "# Produce the targets according to our f(x,z) = 2x - 3z + 5 + noise definition.\n",
        "# In this way, we are basically saying: the weights should be 2 and -3, while the bias is 5.\n",
        "generated_targets = 2*xs - 3*zs + 5 + noise\n",
        "\n",
        "# save into an npz file called \"TF_intro\"\n",
        "np.savez('/content/ANN_DL_ML/TF_intro_b', inputs=generated_inputs, targets=generated_targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ8KsDvKx2CJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data = np.load('/content/ANN_DL_ML/TF_intro_b.npz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wY0ZnNsPx2Hw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a3da717f-3d26-4f54-a2b4-41a9fc0a4d1a"
      },
      "source": [
        "input_size = 2\n",
        "output_size = 1\n",
        "#We build the model, necessary when using tensorflow\n",
        "\n",
        "#tf.keras.layers.Dense(output size) takes the inputs provided to the model and \n",
        "#calculates the dot productof the inputsand he weights and add bias\n",
        "#kernel_initializer and bias initializer initialize weights and biases\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(output_size\n",
        "                         )\n",
        "])\n",
        "#Customize optimizer\n",
        "custom_optimizer = tf.keras.optimizers.SGD(learning_rate=0.02)\n",
        "model.compile(optimizer = custom_optimizer, loss = 'huber_loss')\n",
        "#model.compile(optimizer,loss) configures the model for training\n",
        "\n",
        "#Which deta tensorflow has to fit?\n",
        "#model.fit(inputs,targets) fits (trains) the model\n",
        "\n",
        "model.fit(training_data['inputs'], training_data['targets'], epochs = 100, verbose = 2) # verbose = 0 is for not showing progress bar"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0724 16:28:28.362004 140032364136320 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1000000/1000000 - 42s - loss: 0.2026\n",
            "Epoch 2/100\n",
            "1000000/1000000 - 42s - loss: 0.1718\n",
            "Epoch 3/100\n",
            "1000000/1000000 - 42s - loss: 0.1718\n",
            "Epoch 4/100\n",
            "1000000/1000000 - 42s - loss: 0.1719\n",
            "Epoch 5/100\n",
            "1000000/1000000 - 42s - loss: 0.1718\n",
            "Epoch 6/100\n",
            "1000000/1000000 - 42s - loss: 0.1719\n",
            "Epoch 7/100\n",
            "1000000/1000000 - 42s - loss: 0.1718\n",
            "Epoch 8/100\n",
            "1000000/1000000 - 42s - loss: 0.1719\n",
            "Epoch 9/100\n",
            "1000000/1000000 - 43s - loss: 0.1718\n",
            "Epoch 10/100\n",
            "1000000/1000000 - 42s - loss: 0.1720\n",
            "Epoch 11/100\n",
            "1000000/1000000 - 42s - loss: 0.1720\n",
            "Epoch 12/100\n",
            "1000000/1000000 - 42s - loss: 0.1718\n",
            "Epoch 13/100\n",
            "1000000/1000000 - 42s - loss: 0.1719\n",
            "Epoch 14/100\n",
            "1000000/1000000 - 42s - loss: 0.1719\n",
            "Epoch 15/100\n",
            "1000000/1000000 - 42s - loss: 0.1719\n",
            "Epoch 16/100\n",
            "1000000/1000000 - 42s - loss: 0.1719\n",
            "Epoch 17/100\n",
            "1000000/1000000 - 42s - loss: 0.1718\n",
            "Epoch 18/100\n",
            "1000000/1000000 - 42s - loss: 0.1718\n",
            "Epoch 19/100\n",
            "1000000/1000000 - 42s - loss: 0.1719\n",
            "Epoch 20/100\n",
            "1000000/1000000 - 42s - loss: 0.1718\n",
            "Epoch 21/100\n",
            "1000000/1000000 - 42s - loss: 0.1718\n",
            "Epoch 22/100\n",
            "1000000/1000000 - 42s - loss: 0.1718\n",
            "Epoch 23/100\n",
            "1000000/1000000 - 42s - loss: 0.1718\n",
            "Epoch 24/100\n",
            "1000000/1000000 - 43s - loss: 0.1718\n",
            "Epoch 25/100\n",
            "1000000/1000000 - 42s - loss: 0.1719\n",
            "Epoch 26/100\n",
            "1000000/1000000 - 42s - loss: 0.1719\n",
            "Epoch 27/100\n",
            "1000000/1000000 - 42s - loss: 0.1719\n",
            "Epoch 28/100\n",
            "1000000/1000000 - 42s - loss: 0.1719\n",
            "Epoch 29/100\n",
            "1000000/1000000 - 42s - loss: 0.1719\n",
            "Epoch 30/100\n",
            "1000000/1000000 - 42s - loss: 0.1718\n",
            "Epoch 31/100\n",
            "1000000/1000000 - 42s - loss: 0.1719\n",
            "Epoch 32/100\n",
            "1000000/1000000 - 42s - loss: 0.1718\n",
            "Epoch 33/100\n",
            "1000000/1000000 - 42s - loss: 0.1719\n",
            "Epoch 34/100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJEUwYGix2Kh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.layers[0].get_weights()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yJX7BSMx2M7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights=model.layers[0].get_weights()[0]\n",
        "weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkXCqAEfx2PQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bias=model.layers[0].get_weights()[1]\n",
        "bias"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCS4v-iHx2R5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict_on_batch(training_data['inputs'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXrgjGh-x2UY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict_on_batch(training_data['inputs']).round(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwwOJE0cx2XP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data['inputs'].round(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLh0KU_mx2Zv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(np.squeeze(model.predict_on_batch(training_data['inputs'])),np.squeeze(training_data['targets']))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}