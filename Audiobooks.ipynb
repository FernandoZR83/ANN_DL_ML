{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Audiobooks.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FernandoZR83/ANN_DL_ML/blob/master/Audiobooks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Cqh7BvSGcwS",
        "colab_type": "text"
      },
      "source": [
        "Create a ML models capable to prdict whether a customer will buy an audiobook again or not"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocUDonATYrNL",
        "colab_type": "text"
      },
      "source": [
        "Balancing the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpoaaHlcwDGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgRSGat_bY6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RTr-SFivVGP",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "3e213657-92c2-46e2-c517-fa5042bdbd2f"
      },
      "source": [
        "data = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-92b9ef8a-1c11-4dc6-857b-9b430909fbd8\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-92b9ef8a-1c11-4dc6-857b-9b430909fbd8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Audiobooks_data.csv to Audiobooks_data.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rI5AuDgYhWhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_csv_data = np.loadtxt('Audiobooks_data.csv', delimiter=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ACWPC27wXEX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "24e74a76-38c5-4526-e5a7-33e8088d780f"
      },
      "source": [
        "unscaled_inputs_all = raw_csv_data[:,1:-1]\n",
        "targets_all = raw_csv_data[:,-1] #Last column of the csv\n",
        "\n",
        "print(\"unsclaed_inputs: \", unscaled_inputs_all)\n",
        "print(\"targets: \", targets_all)\n",
        "print(unscaled_inputs_all.shape, targets_all.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unsclaed_inputs:  [[1620.   1620.     19.73 ... 1603.8     5.     92.  ]\n",
            " [2160.   2160.      5.33 ...    0.      0.      0.  ]\n",
            " [2160.   2160.      5.33 ...    0.      0.    388.  ]\n",
            " ...\n",
            " [2160.   2160.      6.14 ...    0.      0.      0.  ]\n",
            " [1620.   1620.      5.33 ...  615.6     0.     90.  ]\n",
            " [1674.   3348.      5.33 ...    0.      0.      0.  ]]\n",
            "targets:  [0. 0. 0. ... 0. 0. 1.]\n",
            "(14084, 10) (14084,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVP4wZjP2dIu",
        "colab_type": "text"
      },
      "source": [
        "Balance the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VvDLIYD2dVu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "4679d853-0e41-4335-d4c7-d5bd2bb30a93"
      },
      "source": [
        "#Our aim first is to know how many ones we have as targets\n",
        "num_one_targets = int(np.sum(targets_all))\n",
        "print(num_one_targets)\n",
        "zero_targets_counter = 0\n",
        "indices_to_remove = [] #This variable can be either list or tuple so we use empty brackets, contains indices to remove\n",
        "\n",
        "#Iterate over the dataset and balance it\n",
        "\n",
        "for i in range(targets_all.shape[0]):\n",
        "  if targets_all[i] == 0:\n",
        "    zero_targets_counter += 1\n",
        "    if zero_targets_counter > num_one_targets:\n",
        "      indices_to_remove.append(i)\n",
        "      #if the target at position i is zero and number of zeros is bigger than number \n",
        "      #of ones, i'll know the indices of the elements that need to be removed\n",
        "\n",
        "unscaled_inputs_equal_priors = np.delete(unscaled_inputs_all, indices_to_remove, axis = 0)\n",
        "targets_equal_priors = np.delete(targets_all, indices_to_remove, axis = 0)\n",
        "print(unscaled_inputs_equal_priors)\n",
        "print(targets_equal_priors)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2237\n",
            "[[1620.   1620.     19.73 ... 1603.8     5.     92.  ]\n",
            " [2160.   2160.      5.33 ...    0.      0.      0.  ]\n",
            " [2160.   2160.      5.33 ...    0.      0.    388.  ]\n",
            " ...\n",
            " [2160.   2160.      5.33 ...    0.      0.      6.  ]\n",
            " [1674.   3348.      7.99 ...    0.      0.      0.  ]\n",
            " [1674.   3348.      5.33 ...    0.      0.      0.  ]]\n",
            "[0. 0. 0. ... 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbydGA2BB7bq",
        "colab_type": "text"
      },
      "source": [
        "Standardize inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpDOTEOW2dYb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "1696ee76-4659-402d-e442-9c147dcf3280"
      },
      "source": [
        "scaled_inputs = preprocessing.scale(unscaled_inputs_equal_priors)\n",
        "print(scaled_inputs)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.21053387 -0.18888517  1.97823887 ...  4.80955413 11.83828419\n",
            "   0.09415043]\n",
            " [ 1.27894497  0.41646744 -0.39082475 ... -0.41569922 -0.20183481\n",
            "  -0.80255852]\n",
            " [ 1.27894497  0.41646744 -0.39082475 ... -0.41569922 -0.20183481\n",
            "   2.979214  ]\n",
            " ...\n",
            " [ 1.27894497  0.41646744 -0.39082475 ... -0.41569922 -0.20183481\n",
            "  -0.7440775 ]\n",
            " [ 0.31737498  1.7482432   0.04679395 ... -0.41569922 -0.20183481\n",
            "  -0.80255852]\n",
            " [ 0.31737498  1.7482432  -0.39082475 ... -0.41569922 -0.20183481\n",
            "  -0.80255852]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jF8422ogEA3x",
        "colab_type": "text"
      },
      "source": [
        "Shuffle data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KBGNgpZ2dd7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# When the data was collected it was actually arranged by date\n",
        "# Shuffle the indices of the data, so the data is not arranged in any way when we feed it.\n",
        "# Since we will be batching, we want the data to be as randomly spread out as possible\n",
        "shuffled_indices = np.arange(scaled_inputs.shape[0])\n",
        "np.random.shuffle(shuffled_indices)\n",
        "\n",
        "# Use the shuffled indices to shuffle the inputs and targets.\n",
        "shuffled_inputs = scaled_inputs[shuffled_indices]\n",
        "shuffled_targets = targets_equal_priors[shuffled_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADb4PzNvGwz1",
        "colab_type": "text"
      },
      "source": [
        "Split the dataset into train, validation and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHtXfsoI2dhP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "63a7f681-c49c-4cf9-a2f0-bf179f480e69"
      },
      "source": [
        "# Count the total number of samples\n",
        "samples_count = shuffled_inputs.shape[0]\n",
        "\n",
        "# Count the samples in each subset, assuming we want 80-10-10 distribution of training, validation, and test.\n",
        "# Naturally, the numbers are integers.\n",
        "train_samples_count = int(0.8 * samples_count)\n",
        "validation_samples_count = int(0.1 * samples_count)\n",
        "\n",
        "# The 'test' dataset contains all remaining data.\n",
        "test_samples_count = samples_count - train_samples_count - validation_samples_count\n",
        "\n",
        "# Create variables that record the inputs and targets for training\n",
        "# In our shuffled dataset, they are the first \"train_samples_count\" observations\n",
        "train_inputs = shuffled_inputs[:train_samples_count]\n",
        "train_targets = shuffled_targets[:train_samples_count]\n",
        "\n",
        "# Create variables that record the inputs and targets for validation.\n",
        "# They are the next \"validation_samples_count\" observations, folllowing the \"train_samples_count\" we already assigned\n",
        "validation_inputs = shuffled_inputs[train_samples_count:train_samples_count+validation_samples_count]\n",
        "validation_targets = shuffled_targets[train_samples_count:train_samples_count+validation_samples_count]\n",
        "\n",
        "# Create variables that record the inputs and targets for test.\n",
        "# They are everything that is remaining.\n",
        "test_inputs = shuffled_inputs[train_samples_count+validation_samples_count:]\n",
        "test_targets = shuffled_targets[train_samples_count+validation_samples_count:]\n",
        "\n",
        "# We balanced our dataset to be 50-50 (for targets 0 and 1), but the training, validation, and test were \n",
        "# taken from a shuffled dataset. Check if they are balanced, too. Note that each time you rerun this code, \n",
        "# you will get different values, as each time they are shuffled randomly.\n",
        "# Normally you preprocess ONCE, so you need not rerun this code once it is done.\n",
        "# If you rerun this whole sheet, the npzs will be overwritten with your newly preprocessed data.\n",
        "\n",
        "# Print the number of targets that are 1s, the total number of samples, and the proportion for training, validation, and test.\n",
        "print(np.sum(train_targets), train_samples_count, np.sum(train_targets) / train_samples_count)\n",
        "print(np.sum(validation_targets), validation_samples_count, np.sum(validation_targets) / validation_samples_count)\n",
        "print(np.sum(test_targets), test_samples_count, np.sum(test_targets) / test_samples_count)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1776.0 3579 0.49622799664710815\n",
            "238.0 447 0.5324384787472036\n",
            "223.0 448 0.49776785714285715\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlgrTLk4HoPd",
        "colab_type": "text"
      },
      "source": [
        "Save the dataset in *.npz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkbGDq8p2dkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the three datasets in *.npz.\n",
        "# In the next lesson, you will see that it is extremely valuable to name them in such a coherent way!\n",
        "\n",
        "np.savez('Audiobooks_data_train', inputs=train_inputs, targets=train_targets)\n",
        "np.savez('Audiobooks_data_validation', inputs=validation_inputs, targets=validation_targets)\n",
        "np.savez('Audiobooks_data_test', inputs=test_inputs, targets=test_targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gH_k5op7_xPe",
        "colab_type": "text"
      },
      "source": [
        "Load data from npz files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvQ4NrxU2dnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "npz = np.load('Audiobooks_data_train.npz')\n",
        "\n",
        "train_inputs=npz['inputs'].astype(np.float)\n",
        "train_targets=npz['targets'].astype(np.int)\n",
        "npz = np.load('Audiobooks_data_validation.npz')\n",
        "\n",
        "validation_inputs, validation_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
        "\n",
        "npz = np.load('Audiobooks_data_test.npz')\n",
        "\n",
        "test_inputs, test_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBUgANG5ElqR",
        "colab_type": "text"
      },
      "source": [
        "Outline the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWqGaMZTDij4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "e1791a4f-428d-47a4-ec14-b77933b808de"
      },
      "source": [
        "input_size = 10\n",
        "output_size = 2 #one per digit\n",
        "hidden_layer_size = 50 #50 nodes per layer\n",
        "#tf.keras.sequential is a function used to \"stack layers\"\n",
        "#Our model's name is model\n",
        "model = tf.keras.Sequential([\n",
        "    #we need to flat images to get them a vector\n",
        "    #First line in sequential function is used to delcare our input layer\n",
        "    #tf.keras.layers.Flatten(input_shape = (28,28,1)),\n",
        "    #tf.keras.layers.Dense(output_size) takes the inputs, provided to the model and calculates the dot product of the\n",
        "    #inputs and the weights and adds the bias.\n",
        "    #This is also where we can apply an activation function\n",
        "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
        "    #We create the second hidden layer the same way\n",
        "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
        "    #Output layer\n",
        "    tf.keras.layers.Dense(output_size, activation = 'softmax')\n",
        "\n",
        "])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0731 03:54:32.423630 140319386036096 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QttZrb0i2db7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.compile(optimizer, loss, metrics) configures the model for training\n",
        "#custimze_model= tf.keras.optimizers.SGD(learning_rate=0.02)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "#model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaWB59PqFAxd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2b544e17-8b9d-43b2-bc6d-5d7911d8de9d"
      },
      "source": [
        "#Batch size\n",
        "batch_size = 10\n",
        "\n",
        "#Choose number of epochs\n",
        "NUM_EPOCHS = 100\n",
        "\n",
        "model.fit(train_inputs, \n",
        "          train_targets,\n",
        "          batch_size = batch_size,          \n",
        "          epochs = NUM_EPOCHS, \n",
        "          validation_data=(validation_inputs, validation_targets),\n",
        "          verbose=1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 3579 samples, validate on 447 samples\n",
            "Epoch 1/100\n",
            "3579/3579 [==============================] - 2s 505us/sample - loss: 0.4744 - acc: 0.7390 - val_loss: 0.3984 - val_acc: 0.7852\n",
            "Epoch 2/100\n",
            "3579/3579 [==============================] - 1s 308us/sample - loss: 0.3835 - acc: 0.7840 - val_loss: 0.3618 - val_acc: 0.8166\n",
            "Epoch 3/100\n",
            "3579/3579 [==============================] - 1s 325us/sample - loss: 0.3645 - acc: 0.8002 - val_loss: 0.3769 - val_acc: 0.7964\n",
            "Epoch 4/100\n",
            "3579/3579 [==============================] - 1s 321us/sample - loss: 0.3569 - acc: 0.8025 - val_loss: 0.3589 - val_acc: 0.7897\n",
            "Epoch 5/100\n",
            "3579/3579 [==============================] - 1s 317us/sample - loss: 0.3538 - acc: 0.8025 - val_loss: 0.3523 - val_acc: 0.8188\n",
            "Epoch 6/100\n",
            "3579/3579 [==============================] - 1s 320us/sample - loss: 0.3495 - acc: 0.8122 - val_loss: 0.3423 - val_acc: 0.8121\n",
            "Epoch 7/100\n",
            "3579/3579 [==============================] - 1s 316us/sample - loss: 0.3428 - acc: 0.8161 - val_loss: 0.3578 - val_acc: 0.7919\n",
            "Epoch 8/100\n",
            "3579/3579 [==============================] - 1s 317us/sample - loss: 0.3407 - acc: 0.8139 - val_loss: 0.3590 - val_acc: 0.8054\n",
            "Epoch 9/100\n",
            "3579/3579 [==============================] - 1s 316us/sample - loss: 0.3365 - acc: 0.8153 - val_loss: 0.3562 - val_acc: 0.7942\n",
            "Epoch 10/100\n",
            "3579/3579 [==============================] - 1s 318us/sample - loss: 0.3380 - acc: 0.8094 - val_loss: 0.3308 - val_acc: 0.8188\n",
            "Epoch 11/100\n",
            "3579/3579 [==============================] - 1s 321us/sample - loss: 0.3389 - acc: 0.8150 - val_loss: 0.3494 - val_acc: 0.8054\n",
            "Epoch 12/100\n",
            "3579/3579 [==============================] - 1s 324us/sample - loss: 0.3371 - acc: 0.8111 - val_loss: 0.3549 - val_acc: 0.7987\n",
            "Epoch 13/100\n",
            "3579/3579 [==============================] - 1s 318us/sample - loss: 0.3304 - acc: 0.8170 - val_loss: 0.3549 - val_acc: 0.7875\n",
            "Epoch 14/100\n",
            "3579/3579 [==============================] - 1s 319us/sample - loss: 0.3348 - acc: 0.8142 - val_loss: 0.3416 - val_acc: 0.7919\n",
            "Epoch 15/100\n",
            "3579/3579 [==============================] - 1s 314us/sample - loss: 0.3280 - acc: 0.8217 - val_loss: 0.3723 - val_acc: 0.7673\n",
            "Epoch 16/100\n",
            "3579/3579 [==============================] - 1s 322us/sample - loss: 0.3284 - acc: 0.8203 - val_loss: 0.3484 - val_acc: 0.7964\n",
            "Epoch 17/100\n",
            "3579/3579 [==============================] - 1s 319us/sample - loss: 0.3291 - acc: 0.8178 - val_loss: 0.3346 - val_acc: 0.8300\n",
            "Epoch 18/100\n",
            "3579/3579 [==============================] - 1s 320us/sample - loss: 0.3295 - acc: 0.8153 - val_loss: 0.3511 - val_acc: 0.7987\n",
            "Epoch 19/100\n",
            "3579/3579 [==============================] - 1s 318us/sample - loss: 0.3266 - acc: 0.8209 - val_loss: 0.3528 - val_acc: 0.7919\n",
            "Epoch 20/100\n",
            "3579/3579 [==============================] - 1s 322us/sample - loss: 0.3294 - acc: 0.8136 - val_loss: 0.3451 - val_acc: 0.8098\n",
            "Epoch 21/100\n",
            "3579/3579 [==============================] - 1s 322us/sample - loss: 0.3264 - acc: 0.8237 - val_loss: 0.3436 - val_acc: 0.8076\n",
            "Epoch 22/100\n",
            "3579/3579 [==============================] - 1s 314us/sample - loss: 0.3251 - acc: 0.8198 - val_loss: 0.3492 - val_acc: 0.8098\n",
            "Epoch 23/100\n",
            "3579/3579 [==============================] - 1s 317us/sample - loss: 0.3244 - acc: 0.8198 - val_loss: 0.3469 - val_acc: 0.8143\n",
            "Epoch 24/100\n",
            "3579/3579 [==============================] - 1s 310us/sample - loss: 0.3231 - acc: 0.8206 - val_loss: 0.3348 - val_acc: 0.8076\n",
            "Epoch 25/100\n",
            "3579/3579 [==============================] - 1s 316us/sample - loss: 0.3217 - acc: 0.8270 - val_loss: 0.3591 - val_acc: 0.7964\n",
            "Epoch 26/100\n",
            "3579/3579 [==============================] - 1s 316us/sample - loss: 0.3240 - acc: 0.8195 - val_loss: 0.3417 - val_acc: 0.8076\n",
            "Epoch 27/100\n",
            "3579/3579 [==============================] - 1s 311us/sample - loss: 0.3217 - acc: 0.8212 - val_loss: 0.3567 - val_acc: 0.8098\n",
            "Epoch 28/100\n",
            "3579/3579 [==============================] - 1s 314us/sample - loss: 0.3205 - acc: 0.8265 - val_loss: 0.3399 - val_acc: 0.8143\n",
            "Epoch 29/100\n",
            "3579/3579 [==============================] - 1s 314us/sample - loss: 0.3204 - acc: 0.8203 - val_loss: 0.3423 - val_acc: 0.8054\n",
            "Epoch 30/100\n",
            "3579/3579 [==============================] - 1s 322us/sample - loss: 0.3212 - acc: 0.8212 - val_loss: 0.3378 - val_acc: 0.8143\n",
            "Epoch 31/100\n",
            "3579/3579 [==============================] - 1s 316us/sample - loss: 0.3228 - acc: 0.8217 - val_loss: 0.3497 - val_acc: 0.8166\n",
            "Epoch 32/100\n",
            "3579/3579 [==============================] - 1s 309us/sample - loss: 0.3191 - acc: 0.8237 - val_loss: 0.3563 - val_acc: 0.7852\n",
            "Epoch 33/100\n",
            "3579/3579 [==============================] - 1s 319us/sample - loss: 0.3183 - acc: 0.8231 - val_loss: 0.3508 - val_acc: 0.7987\n",
            "Epoch 34/100\n",
            "3579/3579 [==============================] - 1s 315us/sample - loss: 0.3200 - acc: 0.8237 - val_loss: 0.3449 - val_acc: 0.8098\n",
            "Epoch 35/100\n",
            "3579/3579 [==============================] - 1s 316us/sample - loss: 0.3208 - acc: 0.8237 - val_loss: 0.3483 - val_acc: 0.8031\n",
            "Epoch 36/100\n",
            "3579/3579 [==============================] - 1s 315us/sample - loss: 0.3178 - acc: 0.8209 - val_loss: 0.3458 - val_acc: 0.8009\n",
            "Epoch 37/100\n",
            "3579/3579 [==============================] - 1s 315us/sample - loss: 0.3163 - acc: 0.8248 - val_loss: 0.3422 - val_acc: 0.7942\n",
            "Epoch 38/100\n",
            "3579/3579 [==============================] - 1s 317us/sample - loss: 0.3215 - acc: 0.8223 - val_loss: 0.3429 - val_acc: 0.8009\n",
            "Epoch 39/100\n",
            "3579/3579 [==============================] - 1s 327us/sample - loss: 0.3199 - acc: 0.8237 - val_loss: 0.3562 - val_acc: 0.8098\n",
            "Epoch 40/100\n",
            "3579/3579 [==============================] - 1s 315us/sample - loss: 0.3230 - acc: 0.8209 - val_loss: 0.3685 - val_acc: 0.7830\n",
            "Epoch 41/100\n",
            "3579/3579 [==============================] - 1s 316us/sample - loss: 0.3176 - acc: 0.8284 - val_loss: 0.3470 - val_acc: 0.7964\n",
            "Epoch 42/100\n",
            "3579/3579 [==============================] - 1s 315us/sample - loss: 0.3158 - acc: 0.8268 - val_loss: 0.3565 - val_acc: 0.8031\n",
            "Epoch 43/100\n",
            "3579/3579 [==============================] - 1s 317us/sample - loss: 0.3135 - acc: 0.8270 - val_loss: 0.3454 - val_acc: 0.8121\n",
            "Epoch 44/100\n",
            "3579/3579 [==============================] - 1s 317us/sample - loss: 0.3188 - acc: 0.8262 - val_loss: 0.3453 - val_acc: 0.8076\n",
            "Epoch 45/100\n",
            "3579/3579 [==============================] - 1s 311us/sample - loss: 0.3190 - acc: 0.8215 - val_loss: 0.3377 - val_acc: 0.8166\n",
            "Epoch 46/100\n",
            "3579/3579 [==============================] - 1s 314us/sample - loss: 0.3165 - acc: 0.8284 - val_loss: 0.3386 - val_acc: 0.8076\n",
            "Epoch 47/100\n",
            "3579/3579 [==============================] - 1s 316us/sample - loss: 0.3195 - acc: 0.8215 - val_loss: 0.3453 - val_acc: 0.8031\n",
            "Epoch 48/100\n",
            "3579/3579 [==============================] - 1s 324us/sample - loss: 0.3166 - acc: 0.8279 - val_loss: 0.3501 - val_acc: 0.8121\n",
            "Epoch 49/100\n",
            "3579/3579 [==============================] - 1s 313us/sample - loss: 0.3170 - acc: 0.8243 - val_loss: 0.3421 - val_acc: 0.7964\n",
            "Epoch 50/100\n",
            "3579/3579 [==============================] - 1s 314us/sample - loss: 0.3166 - acc: 0.8206 - val_loss: 0.3348 - val_acc: 0.8098\n",
            "Epoch 51/100\n",
            "3579/3579 [==============================] - 1s 313us/sample - loss: 0.3144 - acc: 0.8223 - val_loss: 0.3944 - val_acc: 0.7740\n",
            "Epoch 52/100\n",
            "3579/3579 [==============================] - 1s 318us/sample - loss: 0.3153 - acc: 0.8287 - val_loss: 0.3578 - val_acc: 0.8054\n",
            "Epoch 53/100\n",
            "3579/3579 [==============================] - 1s 321us/sample - loss: 0.3157 - acc: 0.8181 - val_loss: 0.3480 - val_acc: 0.8121\n",
            "Epoch 54/100\n",
            "3579/3579 [==============================] - 1s 315us/sample - loss: 0.3166 - acc: 0.8265 - val_loss: 0.3501 - val_acc: 0.8076\n",
            "Epoch 55/100\n",
            "3579/3579 [==============================] - 1s 318us/sample - loss: 0.3164 - acc: 0.8237 - val_loss: 0.3455 - val_acc: 0.8054\n",
            "Epoch 56/100\n",
            "3579/3579 [==============================] - 1s 320us/sample - loss: 0.3173 - acc: 0.8259 - val_loss: 0.3459 - val_acc: 0.7919\n",
            "Epoch 57/100\n",
            "3579/3579 [==============================] - 1s 321us/sample - loss: 0.3133 - acc: 0.8201 - val_loss: 0.3518 - val_acc: 0.8009\n",
            "Epoch 58/100\n",
            "3579/3579 [==============================] - 1s 315us/sample - loss: 0.3150 - acc: 0.8223 - val_loss: 0.3406 - val_acc: 0.8031\n",
            "Epoch 59/100\n",
            "3579/3579 [==============================] - 1s 319us/sample - loss: 0.3107 - acc: 0.8301 - val_loss: 0.3395 - val_acc: 0.8054\n",
            "Epoch 60/100\n",
            "3579/3579 [==============================] - 1s 314us/sample - loss: 0.3132 - acc: 0.8273 - val_loss: 0.3310 - val_acc: 0.8188\n",
            "Epoch 61/100\n",
            "3579/3579 [==============================] - 1s 313us/sample - loss: 0.3126 - acc: 0.8290 - val_loss: 0.3577 - val_acc: 0.7942\n",
            "Epoch 62/100\n",
            "3579/3579 [==============================] - 1s 313us/sample - loss: 0.3175 - acc: 0.8156 - val_loss: 0.3426 - val_acc: 0.7919\n",
            "Epoch 63/100\n",
            "3579/3579 [==============================] - 1s 313us/sample - loss: 0.3120 - acc: 0.8265 - val_loss: 0.3473 - val_acc: 0.7964\n",
            "Epoch 64/100\n",
            "3579/3579 [==============================] - 1s 310us/sample - loss: 0.3156 - acc: 0.8262 - val_loss: 0.3380 - val_acc: 0.8143\n",
            "Epoch 65/100\n",
            "3579/3579 [==============================] - 1s 315us/sample - loss: 0.3158 - acc: 0.8209 - val_loss: 0.3492 - val_acc: 0.7897\n",
            "Epoch 66/100\n",
            "3579/3579 [==============================] - 1s 322us/sample - loss: 0.3115 - acc: 0.8284 - val_loss: 0.3378 - val_acc: 0.7987\n",
            "Epoch 67/100\n",
            "3579/3579 [==============================] - 1s 320us/sample - loss: 0.3119 - acc: 0.8284 - val_loss: 0.3471 - val_acc: 0.7919\n",
            "Epoch 68/100\n",
            "3579/3579 [==============================] - 1s 315us/sample - loss: 0.3150 - acc: 0.8206 - val_loss: 0.3402 - val_acc: 0.8188\n",
            "Epoch 69/100\n",
            "3579/3579 [==============================] - 1s 319us/sample - loss: 0.3146 - acc: 0.8243 - val_loss: 0.3454 - val_acc: 0.8166\n",
            "Epoch 70/100\n",
            "3579/3579 [==============================] - 1s 317us/sample - loss: 0.3146 - acc: 0.8251 - val_loss: 0.3482 - val_acc: 0.7964\n",
            "Epoch 71/100\n",
            "3579/3579 [==============================] - 1s 316us/sample - loss: 0.3107 - acc: 0.8229 - val_loss: 0.3350 - val_acc: 0.8143\n",
            "Epoch 72/100\n",
            "3579/3579 [==============================] - 1s 315us/sample - loss: 0.3102 - acc: 0.8276 - val_loss: 0.3656 - val_acc: 0.7718\n",
            "Epoch 73/100\n",
            "3579/3579 [==============================] - 1s 311us/sample - loss: 0.3126 - acc: 0.8254 - val_loss: 0.3425 - val_acc: 0.8054\n",
            "Epoch 74/100\n",
            "3579/3579 [==============================] - 1s 314us/sample - loss: 0.3117 - acc: 0.8265 - val_loss: 0.3425 - val_acc: 0.8098\n",
            "Epoch 75/100\n",
            "3579/3579 [==============================] - 1s 320us/sample - loss: 0.3109 - acc: 0.8310 - val_loss: 0.3479 - val_acc: 0.7964\n",
            "Epoch 76/100\n",
            "3579/3579 [==============================] - 1s 324us/sample - loss: 0.3084 - acc: 0.8279 - val_loss: 0.3695 - val_acc: 0.7964\n",
            "Epoch 77/100\n",
            "3579/3579 [==============================] - 1s 311us/sample - loss: 0.3120 - acc: 0.8212 - val_loss: 0.3374 - val_acc: 0.8166\n",
            "Epoch 78/100\n",
            "3579/3579 [==============================] - 1s 316us/sample - loss: 0.3127 - acc: 0.8287 - val_loss: 0.3654 - val_acc: 0.7919\n",
            "Epoch 79/100\n",
            "3579/3579 [==============================] - 1s 317us/sample - loss: 0.3122 - acc: 0.8212 - val_loss: 0.3510 - val_acc: 0.8121\n",
            "Epoch 80/100\n",
            "3579/3579 [==============================] - 1s 317us/sample - loss: 0.3093 - acc: 0.8243 - val_loss: 0.3400 - val_acc: 0.7942\n",
            "Epoch 81/100\n",
            "3579/3579 [==============================] - 1s 316us/sample - loss: 0.3095 - acc: 0.8226 - val_loss: 0.3452 - val_acc: 0.7740\n",
            "Epoch 82/100\n",
            "3579/3579 [==============================] - 1s 314us/sample - loss: 0.3127 - acc: 0.8226 - val_loss: 0.3378 - val_acc: 0.8076\n",
            "Epoch 83/100\n",
            "3579/3579 [==============================] - 1s 318us/sample - loss: 0.3103 - acc: 0.8243 - val_loss: 0.3354 - val_acc: 0.8121\n",
            "Epoch 84/100\n",
            "3579/3579 [==============================] - 1s 319us/sample - loss: 0.3124 - acc: 0.8229 - val_loss: 0.3493 - val_acc: 0.7919\n",
            "Epoch 85/100\n",
            "3579/3579 [==============================] - 1s 317us/sample - loss: 0.3065 - acc: 0.8338 - val_loss: 0.3526 - val_acc: 0.8054\n",
            "Epoch 86/100\n",
            "3579/3579 [==============================] - 1s 319us/sample - loss: 0.3091 - acc: 0.8254 - val_loss: 0.3569 - val_acc: 0.8076\n",
            "Epoch 87/100\n",
            "3579/3579 [==============================] - 1s 315us/sample - loss: 0.3088 - acc: 0.8245 - val_loss: 0.3436 - val_acc: 0.8076\n",
            "Epoch 88/100\n",
            "3579/3579 [==============================] - 1s 313us/sample - loss: 0.3093 - acc: 0.8296 - val_loss: 0.3437 - val_acc: 0.8098\n",
            "Epoch 89/100\n",
            "3579/3579 [==============================] - 1s 313us/sample - loss: 0.3092 - acc: 0.8231 - val_loss: 0.3413 - val_acc: 0.8031\n",
            "Epoch 90/100\n",
            "3579/3579 [==============================] - 1s 314us/sample - loss: 0.3107 - acc: 0.8256 - val_loss: 0.3380 - val_acc: 0.8166\n",
            "Epoch 91/100\n",
            "3579/3579 [==============================] - 1s 316us/sample - loss: 0.3082 - acc: 0.8265 - val_loss: 0.3380 - val_acc: 0.8143\n",
            "Epoch 92/100\n",
            "3579/3579 [==============================] - 1s 315us/sample - loss: 0.3106 - acc: 0.8270 - val_loss: 0.3366 - val_acc: 0.8233\n",
            "Epoch 93/100\n",
            "3579/3579 [==============================] - 1s 322us/sample - loss: 0.3079 - acc: 0.8304 - val_loss: 0.3419 - val_acc: 0.7942\n",
            "Epoch 94/100\n",
            "3579/3579 [==============================] - 1s 316us/sample - loss: 0.3079 - acc: 0.8265 - val_loss: 0.3554 - val_acc: 0.7964\n",
            "Epoch 95/100\n",
            "3579/3579 [==============================] - 1s 315us/sample - loss: 0.3071 - acc: 0.8254 - val_loss: 0.3450 - val_acc: 0.7987\n",
            "Epoch 96/100\n",
            "3579/3579 [==============================] - 1s 309us/sample - loss: 0.3072 - acc: 0.8268 - val_loss: 0.3552 - val_acc: 0.8054\n",
            "Epoch 97/100\n",
            "3579/3579 [==============================] - 1s 314us/sample - loss: 0.3044 - acc: 0.8335 - val_loss: 0.3616 - val_acc: 0.7875\n",
            "Epoch 98/100\n",
            "3579/3579 [==============================] - 1s 317us/sample - loss: 0.3087 - acc: 0.8262 - val_loss: 0.3439 - val_acc: 0.7919\n",
            "Epoch 99/100\n",
            "3579/3579 [==============================] - 1s 316us/sample - loss: 0.3075 - acc: 0.8307 - val_loss: 0.3453 - val_acc: 0.8009\n",
            "Epoch 100/100\n",
            "3579/3579 [==============================] - 1s 318us/sample - loss: 0.3091 - acc: 0.8282 - val_loss: 0.3495 - val_acc: 0.8009\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe7dfa20fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqXqKZbqI5gL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "88df9f79-c597-419f-930f-5d8d3fbbfc4b"
      },
      "source": [
        "#Overfitted model\n",
        "#Early stop method need to be implemented. We will use callbacks\n",
        "#Batch size\n",
        "batch_size = 10\n",
        "\n",
        "#Choose number of epochs\n",
        "NUM_EPOCHS = 100\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
        "\n",
        "model.fit(train_inputs, \n",
        "          train_targets,\n",
        "          batch_size = batch_size,          \n",
        "          epochs = NUM_EPOCHS, \n",
        "          callbacks = [early_stopping],\n",
        "          validation_data=(validation_inputs, validation_targets),\n",
        "          verbose=1)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 3579 samples, validate on 447 samples\n",
            "Epoch 1/100\n",
            "3579/3579 [==============================] - 2s 497us/sample - loss: 0.4580 - acc: 0.7497 - val_loss: 0.3844 - val_acc: 0.7964\n",
            "Epoch 2/100\n",
            "3579/3579 [==============================] - 1s 302us/sample - loss: 0.3745 - acc: 0.7913 - val_loss: 0.3478 - val_acc: 0.8098\n",
            "Epoch 3/100\n",
            "3579/3579 [==============================] - 1s 309us/sample - loss: 0.3587 - acc: 0.7958 - val_loss: 0.3454 - val_acc: 0.8233\n",
            "Epoch 4/100\n",
            "3579/3579 [==============================] - 1s 306us/sample - loss: 0.3486 - acc: 0.8066 - val_loss: 0.3318 - val_acc: 0.8277\n",
            "Epoch 5/100\n",
            "3579/3579 [==============================] - 1s 307us/sample - loss: 0.3432 - acc: 0.8016 - val_loss: 0.3239 - val_acc: 0.8210\n",
            "Epoch 6/100\n",
            "3579/3579 [==============================] - 1s 308us/sample - loss: 0.3363 - acc: 0.8094 - val_loss: 0.3072 - val_acc: 0.8367\n",
            "Epoch 7/100\n",
            "3579/3579 [==============================] - 1s 306us/sample - loss: 0.3373 - acc: 0.8100 - val_loss: 0.3136 - val_acc: 0.8345\n",
            "Epoch 8/100\n",
            "3579/3579 [==============================] - 1s 309us/sample - loss: 0.3334 - acc: 0.8136 - val_loss: 0.3151 - val_acc: 0.8456\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9e79478940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izEvXkEjFA-f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c15a710a-bc90-49cb-e9ff-c984acc63e11"
      },
      "source": [
        "\n",
        "#to store in variables test loss and test accuracy, we write:\n",
        "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "448/448 [==============================] - 0s 69us/sample - loss: 0.3582 - acc: 0.7991\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DkvGg55FBBl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef2c397b-8cc1-4f53-881d-0f353b1e65e6"
      },
      "source": [
        "print('Test loss: {0:.2f}, Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.36, Test accuracy: 79.91%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LmFxNRJFBEp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "d96a3941-26a9-457c-9e32-c4a52c537451"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(np.squeeze(model.predict_on_batch(train_inputs)),np.squeeze(train_targets))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f9e4093e4a8>,\n",
              " <matplotlib.lines.Line2D at 0x7f9e4093e5f8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncVcURWmHqHFXFEVph/x/dlPIR7qHc4IAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBmjOoq-FBHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o4P1p9SFBKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}